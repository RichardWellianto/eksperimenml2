{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#LOAD DATA CSV menjadi array of dataset dan array of label\n",
    "def load_csv(filename):\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "        line_count = 0\n",
    "        #MAKE DUMMY ARRAY\n",
    "        X = np.zeros((1,13))\n",
    "        label = np.array(None)\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                #NOT USING THE COLUMN NAMES\n",
    "#                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                #ADD ELEMENT AND LABEL TO ARRAY\n",
    "                line = np.empty(0)\n",
    "                for i in range(13):\n",
    "                    if row[i] == \"?\":\n",
    "                        line = np.append(line, None)\n",
    "                    else:\n",
    "                        line = np.append(line, row[i])\n",
    "                X = np.append(X, np.array([line]), axis=0)\n",
    "                label = np.append(label, row[13])\n",
    "                line_count += 1\n",
    "        #REMOVE DUMMY ELEMENT\n",
    "        X = np.delete(X, 0, 0)\n",
    "        label = np.delete(label, 0)\n",
    "    return X, label\n",
    "\n",
    "def sort_X(X):\n",
    "    arr = [[] for i in range(len(X[0]))]\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            if X[i][j] != None:\n",
    "                arr[j].append(X[i][j])\n",
    "    for i in range(len(X[0])):\n",
    "        arr[i].sort()\n",
    "    return arr\n",
    "\n",
    "def exchange_question_mark(X, arr):\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            if X[i][j] == None:\n",
    "                X[i][j] = arr[j][len(arr[j])//2]\n",
    "    return X\n",
    "\n",
    "def normalize(X, arr):\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            #Age\n",
    "            if j == 0:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "            #Cp\n",
    "            elif j == 2:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "            #Trestbps\n",
    "            elif j == 3:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "            #Chol\n",
    "            elif j == 4:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "            #Thalach\n",
    "            elif j == 7:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "            #Thal\n",
    "            elif j == 12:\n",
    "                X[i][j] = float(X[i][j]) / float(arr[j][len(arr[j])//2])\n",
    "    return X\n",
    "\n",
    "X1, label1 = load_csv('train.csv')\n",
    "arr1 = sort_X(X1)\n",
    "X1 = exchange_question_mark(X1, arr1)\n",
    "X1 = normalize(X1, arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, label2 = load_csv('train.csv')\n",
    "X3, label3 = load_csv('test.csv')\n",
    "X2 = np.append(X2, X3, axis=0)\n",
    "label2 = np.append(label2, label3)\n",
    "arr2 = sort_X(X2)\n",
    "X2 = exchange_question_mark(X2, arr2)\n",
    "X2 = normalize(X2, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering_model_1 = AgglomerativeClustering(linkage='complete').fit(X1)\n",
    "clustering_model_2 = AgglomerativeClustering(linkage='complete').fit(X2)\n",
    "print(clustering_model_1.labels_)\n",
    "print(clustering_model_2.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'0': 118, '1': 142}, 0: {'1': 58, '0': 882}}\n",
      "0.8533333333333334\n",
      "{0: {'0': 1061, '1': 226}, 1: {'1': 2}}\n",
      "0.8246702870442203\n"
     ]
    }
   ],
   "source": [
    "#ASUMSI labelclust dan label ukuran sama\n",
    "def purity(labelclust, label):\n",
    "    labelmap = {}\n",
    "    summax = 0\n",
    "    for i in range(len(labelclust)):\n",
    "        if labelclust[i] not in labelmap.keys():\n",
    "            labelmap[labelclust[i]] = {}\n",
    "        if label[i] not in labelmap[labelclust[i]].keys():\n",
    "            labelmap[labelclust[i]][label[i]] = 1\n",
    "        else:\n",
    "            labelmap[labelclust[i]][label[i]] += 1\n",
    "    print(labelmap)\n",
    "    for el in labelmap.keys():\n",
    "        summax += max(labelmap[el].values())\n",
    "    return summax/len(labelclust)\n",
    "                \n",
    "print(purity(clustering_model_1.labels_, label1))\n",
    "print(purity(clustering_model_2.labels_, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'0': 14, '1': 3}, 1: {'1': 25, '0': 480}, 2: {'0': 9}, -1: {'1': 50, '0': 25}, 3: {'1': 38}, 4: {'0': 14}, 5: {'0': 8}, 6: {'0': 72}, 7: {'0': 121}, 8: {'0': 5}, 9: {'1': 4, '0': 43}, 10: {'0': 23, '1': 5}, 11: {'1': 9, '0': 17}, 12: {'1': 9}, 13: {'0': 23}, 14: {'1': 4, '0': 50}, 15: {'0': 32, '1': 7}, 16: {'1': 39, '0': 19}, 17: {'0': 9}, 18: {'0': 8, '1': 1}, 19: {'1': 6}, 20: {'0': 5}, 21: {'0': 14}, 22: {'0': 9}}\n",
      "0.915\n",
      "{0: {'0': 14, '1': 4}, 1: {'1': 31, '0': 501}, 2: {'0': 9}, -1: {'1': 60, '0': 37}, 3: {'1': 39}, 4: {'0': 14}, 5: {'0': 8}, 6: {'0': 76}, 7: {'0': 138}, 8: {'0': 5}, 9: {'1': 5, '0': 43}, 10: {'0': 23, '1': 5}, 11: {'1': 9, '0': 18}, 12: {'1': 9}, 13: {'0': 25, '1': 1}, 14: {'1': 4, '0': 53}, 15: {'0': 33, '1': 7}, 16: {'1': 42, '0': 19}, 17: {'0': 9}, 18: {'0': 8, '1': 1}, 19: {'1': 6}, 20: {'0': 5}, 21: {'0': 14}, 22: {'0': 9}, 23: {'1': 5}}\n",
      "0.9045771916214119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clustering_DBSCAN_model_1 = DBSCAN().fit(X1)\n",
    "clustering_DBSCAN_model_2 = DBSCAN().fit(X2)\n",
    "print(purity(clustering_DBSCAN_model_1.labels_, label1))\n",
    "print(purity(clustering_DBSCAN_model_2.labels_, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.66291344e-01 7.39080460e-01 8.52490421e-01 9.98422882e-01\n",
      "  9.84331034e-01 7.01149425e-02 2.17241379e-01 1.00003964e+00\n",
      "  5.05747126e-02 2.72004641e-15 1.99425287e+00 0.00000000e+00\n",
      "  1.00076628e+00]\n",
      " [1.00803958e+00 5.90909091e-01 1.05151515e+00 1.02713178e+00\n",
      "  1.02909091e+00 5.15151515e-02 1.54545455e-01 9.38328109e-01\n",
      "  5.66666667e-01 1.37878788e+00 1.99393939e+00 0.00000000e+00\n",
      "  9.99494949e-01]]\n",
      "[[9.64137111e-01 7.31391586e-01 8.58324344e-01 1.00034286e+00\n",
      "  9.82511327e-01 6.90399137e-02 2.12513484e-01 1.00029759e+00\n",
      "  4.96224380e-02 5.39374326e-04 1.99352751e+00 0.00000000e+00\n",
      "  9.99820209e-01]\n",
      " [1.01336115e+00 6.13259669e-01 1.06261510e+00 1.03145745e+00\n",
      "  1.03146961e+00 5.80110497e-02 1.74033149e-01 9.31929891e-01\n",
      "  5.88397790e-01 1.41298343e+00 1.98618785e+00 0.00000000e+00\n",
      "  9.95856354e-01]]\n",
      "{1: {'0': 178, '1': 152}, 0: {'1': 48, '0': 822}}\n",
      "0.8333333333333334\n",
      "{1: {'0': 189, '1': 173}, 0: {'1': 55, '0': 872}}\n",
      "0.8231186966640807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clustering_KMeans_model_1 = KMeans(2, 'k-means++').fit(X1)\n",
    "clustering_KMeans_model_2 = KMeans(2, 'k-means++').fit(X2)\n",
    "center_X1 = clustering_KMeans_model_1.cluster_centers_\n",
    "center_X2 = clustering_KMeans_model_2.cluster_centers_\n",
    "print(center_X1)\n",
    "print(center_X2)\n",
    "print(purity(clustering_KMeans_model_1.labels_, label1))\n",
    "print(purity(clustering_KMeans_model_2.labels_, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
